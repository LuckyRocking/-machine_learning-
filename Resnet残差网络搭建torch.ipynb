{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import Linear,Conv2d,BatchNorm2d,MaxPool2d,Flatten,G\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from typing import Callable, Any, Optional, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本卷积层\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int,**kwargs:Any) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,**kwargs,bias=True)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x为tensor 输出也为tensor\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.bn(x1)\n",
    "        return F.relu(x2, inplace=True)\n",
    "\n",
    "#残差单元\n",
    "class ResidualUnit(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs:Any) :\n",
    "        super().__init__()\n",
    "        self.conv2d_block1=BasicConv2d(in_channels,out_channels,kernel_size=3,**kwargs)\n",
    "        self.conv2d_block2=BasicConv2d(out_channels,out_channels,kernel_size=3,strides=1)\n",
    "        self.skip_block1=BasicConv2d(in_channels,out_channels,kernel_size=1,**kwargs)\n",
    "    #定义前向传播\n",
    "    def forward(self,x):\n",
    "        residual1=self.conv2d_block1(x)\n",
    "        residual=self.conv2d_block2(residual1)\n",
    "        fx=self.skip_block1(x)     \n",
    "        return fx+residual\n",
    "        \n",
    "\n",
    "#搭建Resnet34-CNN\n",
    "class ResidualNet(nn.Module):\n",
    "    def __init__(self, in_channels: int, conv_block: Optional[Callable[..., nn.Module]] = None,residual_block:Optional[Callable[..., nn.Module]]=None):\n",
    "        super().__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        if residual_block is None:\n",
    "            residual_unit=ResidualUnit\n",
    "        self.conv1=conv_block(in_channels,64,strides=2)\n",
    "        self.residual_block=[residual_unit(64,64),residual_unit(64,64),residual_unit(64,64),residual_unit(64,128),residual_unit(128,128),residual_unit(128,128),residual_unit(128,128),residual_unit(128,256),residual_unit(256,256),\n",
    "                            residual_unit(256,256),residual_unit(256,256),residual_unit(256,256),residual_unit(256,256),residual_unit(256,512),residual_unit(512,512),residual_unit(512,512)]\n",
    "        self.flatten=Flatten()\n",
    "        self.softmax=Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=F.max_pool2d(x1)\n",
    "        for layers in self.residual_block:\n",
    "            x2=layers(x2)\n",
    "        x3 = F.adaptive_avg_pool2d(x2,(1,1))\n",
    "        x4=self.flatten(x3)\n",
    "        oupput=self.softmax(x4)\n",
    "        return oupput\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e450050b432e843bda3c41bf3272c133bfc370a7003f3e377e27f87a49ce1127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
